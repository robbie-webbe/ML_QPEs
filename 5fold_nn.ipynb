{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35f30682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from random import sample, shuffle\n",
    "\n",
    "n = 5 \n",
    "feat_lists = []\n",
    "\n",
    "#import the feature sets and split to features and labels\n",
    "for i in range(n):\n",
    "    feat_lists.append(np.loadtxt('Features/'+str(n)+'fold_cvsets/kfold_'+str(n)+'featuresets_set'+str(i)+'.csv',delimiter=','))\n",
    "    \n",
    "features_array = np.zeros((n,len(feat_lists[0]),14))\n",
    "labels_array = np.zeros((n,len(feat_lists[0])))\n",
    "\n",
    "#import the feature and label sets\n",
    "for i in range(n):\n",
    "    features_array[i,:,:] = feat_lists[i][:,0:-1]\n",
    "    labels_array[i,:] = feat_lists[i][:,-1]\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b9c945",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 15:01:25.959238: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 2s 868us/step - loss: 1.3562 - accuracy: 0.8603\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 2s 834us/step - loss: 0.3083 - accuracy: 0.9036\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 2s 846us/step - loss: 0.3120 - accuracy: 0.9075\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 2s 873us/step - loss: 0.2936 - accuracy: 0.9128\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 2s 859us/step - loss: 0.2921 - accuracy: 0.9137\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 2s 823us/step - loss: 0.2932 - accuracy: 0.9139\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 2s 863us/step - loss: 0.2859 - accuracy: 0.9153\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 2s 864us/step - loss: 0.2862 - accuracy: 0.9161\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 2s 827us/step - loss: 0.2873 - accuracy: 0.9162\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 2s 854us/step - loss: 0.2872 - accuracy: 0.9165\n",
      "625/625 - 1s - loss: 0.2255 - accuracy: 0.9261 - 502ms/epoch - 804us/step\n",
      "\n",
      "Test accuracy: 0.9260500073432922\n",
      "Iteration 1\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 2s 845us/step - loss: 0.3101 - accuracy: 0.9001\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 2s 852us/step - loss: 0.2815 - accuracy: 0.9121\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 2s 848us/step - loss: 0.2791 - accuracy: 0.9141\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 2s 875us/step - loss: 0.2785 - accuracy: 0.9158\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 2s 845us/step - loss: 0.2711 - accuracy: 0.9181\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 2s 856us/step - loss: 0.2665 - accuracy: 0.9195\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 2s 864us/step - loss: 0.2691 - accuracy: 0.9194\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 2s 832us/step - loss: 0.2633 - accuracy: 0.9203\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 2s 843us/step - loss: 0.2645 - accuracy: 0.9216\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 2s 861us/step - loss: 0.2585 - accuracy: 0.9223\n",
      "625/625 - 1s - loss: 0.3104 - accuracy: 0.9288 - 556ms/epoch - 889us/step\n",
      "\n",
      "Test accuracy: 0.9287999868392944\n",
      "Iteration 2\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 2s 836us/step - loss: 0.5644 - accuracy: 0.8800\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3044 - accuracy: 0.9065\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 2s 867us/step - loss: 0.2778 - accuracy: 0.9140\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 2s 845us/step - loss: 0.2708 - accuracy: 0.9171\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 2s 840us/step - loss: 0.2666 - accuracy: 0.9183\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 2s 870us/step - loss: 0.2670 - accuracy: 0.9183\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 2s 839us/step - loss: 0.2715 - accuracy: 0.9180\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 2s 865us/step - loss: 0.2643 - accuracy: 0.9200\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 2s 859us/step - loss: 0.2689 - accuracy: 0.9197\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 2s 860us/step - loss: 0.2552 - accuracy: 0.9225\n",
      "625/625 - 0s - loss: 0.2527 - accuracy: 0.9302 - 460ms/epoch - 736us/step\n",
      "\n",
      "Test accuracy: 0.9302499890327454\n",
      "Iteration 3\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 2s 846us/step - loss: 1.0356 - accuracy: 0.8714\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 2s 849us/step - loss: 0.2939 - accuracy: 0.9078\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 2s 871us/step - loss: 0.2969 - accuracy: 0.9093\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 2s 845us/step - loss: 0.3000 - accuracy: 0.9094\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 2s 845us/step - loss: 0.2943 - accuracy: 0.9118\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 2s 844us/step - loss: 0.2851 - accuracy: 0.9146\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 2s 859us/step - loss: 0.2821 - accuracy: 0.9149\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 2s 875us/step - loss: 0.2909 - accuracy: 0.9151\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 2s 829us/step - loss: 0.2790 - accuracy: 0.9171\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 2s 846us/step - loss: 0.2749 - accuracy: 0.9184\n",
      "625/625 - 0s - loss: 0.2525 - accuracy: 0.9315 - 480ms/epoch - 769us/step\n",
      "\n",
      "Test accuracy: 0.9315000176429749\n",
      "Iteration 4\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 2s 840us/step - loss: 0.6326 - accuracy: 0.8442\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 2s 851us/step - loss: 0.3155 - accuracy: 0.9021\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 2s 829us/step - loss: 0.3072 - accuracy: 0.9058\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 2s 855us/step - loss: 0.3062 - accuracy: 0.9090\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 2s 889us/step - loss: 0.2921 - accuracy: 0.9123\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 2s 918us/step - loss: 0.2923 - accuracy: 0.9139\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 2s 956us/step - loss: 0.2918 - accuracy: 0.9141\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 2s 942us/step - loss: 0.2884 - accuracy: 0.9152\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 2s 947us/step - loss: 0.2841 - accuracy: 0.9172\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 2s 988us/step - loss: 0.2815 - accuracy: 0.9182\n",
      "625/625 - 1s - loss: 0.2319 - accuracy: 0.9291 - 580ms/epoch - 929us/step\n",
      "\n",
      "Test accuracy: 0.929099977016449\n"
     ]
    }
   ],
   "source": [
    "for i in range(n):\n",
    "    #create the training data set\n",
    "    training_feats = np.delete(features_array,i,0)\n",
    "    training_feats = np.reshape(training_feats,(training_feats.shape[0]*training_feats.shape[1],training_feats.shape[2]))\n",
    "    training_labels = np.delete(labels_array,i,0)\n",
    "    training_labels = np.reshape(training_labels,(training_labels.shape[0]*training_labels.shape[1]))\n",
    "    \n",
    "    #extract the validation data set\n",
    "    valid_feats = features_array[i]\n",
    "    valid_labels = labels_array[i,:]\n",
    "    \n",
    "    print('Iteration '+str(i))\n",
    "    #create and test models\n",
    "    model = tf.keras.Sequential([tf.keras.layers.Dense(14, activation='relu'), tf.keras.layers.Dense(2)])\n",
    "    model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(training_feats, training_labels, epochs=10)\n",
    "    test_loss, test_acc = model.evaluate(valid_feats, valid_labels, verbose=2)\n",
    "\n",
    "    print('\\nTest accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8499d050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
