{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35f30682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from random import sample, shuffle\n",
    "\n",
    "n = 5 \n",
    "feat_lists = []\n",
    "\n",
    "#import the feature sets and split to features and labels\n",
    "for i in range(n):\n",
    "    feat_lists.append(np.loadtxt('Features/'+str(n)+'fold_cvsets/kfold_'+str(n)+'featuresets_set'+str(i)+'.csv',delimiter=','))\n",
    "    \n",
    "features_array = np.zeros((n,len(feat_lists[0]),14))\n",
    "labels_array = np.zeros((n,len(feat_lists[0])))\n",
    "\n",
    "#import the feature and label sets\n",
    "for i in range(n):\n",
    "    features_array[i,:,:] = feat_lists[i][:,0:-1]\n",
    "    labels_array[i,:] = feat_lists[i][:,-1]\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b9c945",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 \n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 11:50:25.194822: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 2s 739us/step - loss: 0.8688 - accuracy: 0.8936\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 2s 767us/step - loss: 0.2807 - accuracy: 0.9125\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 2s 827us/step - loss: 0.2758 - accuracy: 0.9162\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 2s 828us/step - loss: 0.2829 - accuracy: 0.9161\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 2s 826us/step - loss: 0.2790 - accuracy: 0.9172\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 2s 826us/step - loss: 0.2756 - accuracy: 0.9193\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 2s 827us/step - loss: 0.2731 - accuracy: 0.9194\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 2s 859us/step - loss: 0.2659 - accuracy: 0.9214\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 2s 822us/step - loss: 0.2665 - accuracy: 0.9212\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 2s 835us/step - loss: 0.2632 - accuracy: 0.9215\n",
      "625/625 - 1s - loss: 0.2626 - accuracy: 0.9196 - 527ms/epoch - 843us/step\n",
      "\n",
      "Test accuracy: 0.9196000099182129 \n",
      "\n",
      "Iteration 2 \n",
      "\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 2s 821us/step - loss: 4.0897 - accuracy: 0.8772\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 2s 863us/step - loss: 0.2943 - accuracy: 0.9072\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 2s 903us/step - loss: 0.2886 - accuracy: 0.9120\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 2s 866us/step - loss: 0.2796 - accuracy: 0.9147\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 2s 837us/step - loss: 0.2808 - accuracy: 0.9156\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 2s 774us/step - loss: 0.2771 - accuracy: 0.9168\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 2s 711us/step - loss: 0.2864 - accuracy: 0.9160\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 2s 704us/step - loss: 0.2786 - accuracy: 0.9173\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 2s 711us/step - loss: 0.2707 - accuracy: 0.9186\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 2s 714us/step - loss: 0.2732 - accuracy: 0.9199\n",
      "625/625 - 0s - loss: 0.2220 - accuracy: 0.9309 - 497ms/epoch - 795us/step\n",
      "\n",
      "Test accuracy: 0.930899977684021 \n",
      "\n",
      "Iteration 3 \n",
      "\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 2s 727us/step - loss: 0.5498 - accuracy: 0.8974\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 2s 722us/step - loss: 0.2896 - accuracy: 0.9120\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 2s 708us/step - loss: 0.2883 - accuracy: 0.9141\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 2s 704us/step - loss: 0.2920 - accuracy: 0.9146\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 2s 890us/step - loss: 0.2724 - accuracy: 0.9182\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 2s 965us/step - loss: 0.2659 - accuracy: 0.9203\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 2s 856us/step - loss: 0.2820 - accuracy: 0.9180\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 2s 871us/step - loss: 0.2703 - accuracy: 0.9211\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 2s 864us/step - loss: 0.2646 - accuracy: 0.9220\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 2s 893us/step - loss: 0.2654 - accuracy: 0.9221\n",
      "625/625 - 0s - loss: 0.2461 - accuracy: 0.9308 - 465ms/epoch - 744us/step\n",
      "\n",
      "Test accuracy: 0.9307500123977661 \n",
      "\n",
      "Iteration 4 \n",
      "\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 2s 848us/step - loss: 1.4542 - accuracy: 0.8809\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 2s 896us/step - loss: 0.3109 - accuracy: 0.9037\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 2s 870us/step - loss: 0.3020 - accuracy: 0.9087\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 2s 871us/step - loss: 0.2952 - accuracy: 0.9108\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 2s 895us/step - loss: 0.3002 - accuracy: 0.9108\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 2s 863us/step - loss: 0.2895 - accuracy: 0.9145\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 2s 889us/step - loss: 0.2833 - accuracy: 0.9153\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 2s 892us/step - loss: 0.2793 - accuracy: 0.9169\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 2s 913us/step - loss: 0.2895 - accuracy: 0.9151\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 2s 876us/step - loss: 0.2860 - accuracy: 0.9161\n",
      "625/625 - 0s - loss: 0.2853 - accuracy: 0.9304 - 461ms/epoch - 738us/step\n",
      "\n",
      "Test accuracy: 0.9303500056266785 \n",
      "\n",
      "Iteration 5 \n",
      "\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 2s 861us/step - loss: 1.9547 - accuracy: 0.8761\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 2s 842us/step - loss: 0.2891 - accuracy: 0.9091\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 2s 920us/step - loss: 0.3005 - accuracy: 0.9095\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 2s 847us/step - loss: 0.2955 - accuracy: 0.9126\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 2s 884us/step - loss: 0.2921 - accuracy: 0.9131\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 2s 884us/step - loss: 0.2857 - accuracy: 0.9153\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 2s 860us/step - loss: 0.2954 - accuracy: 0.9143\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 2s 710us/step - loss: 0.2826 - accuracy: 0.9167\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 2s 719us/step - loss: 0.2854 - accuracy: 0.9171\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 2s 716us/step - loss: 0.2862 - accuracy: 0.9172\n",
      "625/625 - 0s - loss: 0.2110 - accuracy: 0.9312 - 426ms/epoch - 682us/step\n",
      "\n",
      "Test accuracy: 0.9312499761581421 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(n):\n",
    "    #create the training data set\n",
    "    training_feats = np.delete(features_array,i,0)\n",
    "    training_feats = np.reshape(training_feats,(training_feats.shape[0]*training_feats.shape[1],training_feats.shape[2]))\n",
    "    training_labels = np.delete(labels_array,i,0)\n",
    "    training_labels = np.reshape(training_labels,(training_labels.shape[0]*training_labels.shape[1]))\n",
    "    \n",
    "    #extract the validation data set\n",
    "    valid_feats = features_array[i]\n",
    "    valid_labels = labels_array[i,:]\n",
    "    \n",
    "    print('Iteration '+str(i+1), '\\n')\n",
    "    #create and test models\n",
    "    model = tf.keras.Sequential([tf.keras.layers.Dense(14, activation='relu'), tf.keras.layers.Dense(2)])\n",
    "    model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(training_feats, training_labels, epochs=10)\n",
    "    test_loss, test_acc = model.evaluate(valid_feats, valid_labels, verbose=2)\n",
    "\n",
    "    print('\\nTest accuracy:', test_acc, '\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8499d050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
